2023-01-20 14:27:33,058 CRIT Supervisor is running as root.  Privileges were not dropped because no user is specified in the config file.  If you intend to run as root, you can set user=root in the config file to avoid this message.
2023-01-20 14:27:33,060 INFO supervisord started with pid 7
2023-01-20 14:27:34,062 INFO spawned: 'nginx' with pid 10
2023-01-20 14:27:34,063 INFO spawned: 'app' with pid 11
Bottle v0.12.23 server starting up (using WSGIRefServer())...
Listening on http://localhost:5000/
Hit Ctrl-C to quit.

2023-01-20 14:27:35,826 INFO success: nginx entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)
2023-01-20 14:27:35,826 INFO success: app entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)
[CTRL] POST /setup
[Time: 20.01.23 14:27:43] [Level: info] id: 69acf3b48408d58c
[Time: 20.01.23 14:27:43] [Level: info] coordinator: True
[Time: 20.01.23 14:27:43] [Level: info] clients: ['69acf3b48408d58c', 'ef2faf2923e76eaa']
[Time: 20.01.23 14:27:43] [Level: info] state: initial
127.0.0.1 - - [20/Jan/2023 14:27:43] "POST /api/setup HTTP/1.0" 200 0
[Time: 20.01.23 14:27:43] [Level: info] [State: initial]  Splits order:
[Time: 20.01.23 14:27:43] [Level: info] [State: initial] Split 0: /mnt/input[CTRL] GET /status

[Time: 20.01.23 14:27:43] [Level: info] [State: initial] Getting sample shape from /mnt/input/mnist.npz dataset
127.0.0.1 - - [20/Jan/2023 14:27:43] "GET /api/status HTTP/1.0" 200 149
[Time: 20.01.23 14:27:44] [Level: info] Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/FeatureCloud/app/engine/app.py", line 172, in guarded_run
    self.run()
  File "/usr/local/lib/python3.8/site-packages/FeatureCloud/app/engine/app.py", line 187, in run
    transition = self.current_state.run()
  File "/app/states.py", line 21, in run
    super().run()
  File "/app/utils/pytorch/states.py", line 34, in run
    client_model, train_loaders, test_loaders = self.load_clients_data(data_cv_folds, dl)
  File "/app/utils/pytorch/states.py", line 89, in load_clients_data
    client_model = self.build_client_model(dl.sample_data_loader, device)
  File "/app/utils/pytorch/states.py", line 73, in build_client_model
    model = Model(model_class, config, self.config['train_config'], device)
  File "/app/utils/pytorch/DeepModel.py", line 77, in __init__
    self.model.to(device=self.device)
  File "/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 852, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 530, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 552, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 850, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
  File "/usr/local/lib/python3.8/site-packages/torch/cuda/__init__.py", line 166, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled

127.0.0.1 - - [20/Jan/2023 14:27:46] "GET /api/status HTTP/1.0" 200 138
[CTRL] GET /status
